{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMEQK_x18nda"
      },
      "source": [
        "\n",
        "#Neuroguard, Machine learning for intracranial pressure monitoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLPGN5Yd37Gg"
      },
      "source": [
        "##Specific objectives\n",
        "1. development a algoritm\n",
        "\n",
        "##Sections of the project\n",
        "1. Set up the environment\n",
        "2. Download relevant databases and resources\n",
        "3. Preprocessing \n",
        "4. Create new development space with SAM\n",
        "5. Assign SAM configuration\n",
        "6. Testing on random images for segmentation\n",
        "7. Check out our WEB page\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zJqP5cg2UWL"
      },
      "source": [
        "<a id=\"1.setup\"></a>\n",
        "#1. Set Up the environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RWiHJTa7ttl"
      },
      "outputs": [],
      "source": [
        "!gdown --id 1RplOOrelIOycetRtEpoYrLmFZLtsJZUX\n",
        "!7z x SAM_workshop_data2.zip\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import sys\n",
        "!{sys.executable} -m pip install opencv-python matplotlib\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n",
        "!{sys.executable} -m pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "!{sys.executable} -m pip install lvis\n",
        "!{sys.executable} -m pip install lvis-api/.\n",
        "!{sys.executable} -m pip install tqdm\n",
        "\n",
        "from copy import deepcopy\n",
        "import logging\n",
        "from collections import defaultdict\n",
        "from collections import OrderedDict\n",
        "\n",
        "from lvis.lvis import LVIS\n",
        "import pycocotools.mask as mask_utils\n",
        "import datetime\n",
        "\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "from lvis import LVIS, LVISVis, LVISResults, LVISEval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZFvvZLY8m1k"
      },
      "source": [
        "#2. Download relevant databases and resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8-6u-5H95-6"
      },
      "outputs": [],
      "source": [
        "!wget -O kaggle.json https://raw.githubusercontent.com/aarevalom0/NeuroGuard/refs/heads/main/kaggle.json\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# Files of Kaggle competitions\n",
        "!kaggle competitions download -c aptos2019-blindness-detection\n",
        "!unzip aptos2019-blindness-detection.zip -d ./dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#3. Preprocesing images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imagen = cv2.imread('/content/dataset/test_images/006efc72b638.png')\n",
        "imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title(\"Imagen Original\")\n",
        "plt.imshow(imagen)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUBxKp3xEead"
      },
      "source": [
        "# 4. Create new development space with SAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6N_UUIiLEw_Z"
      },
      "outputs": [],
      "source": [
        "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "\n",
        "mask_generator = SamAutomaticMaskGenerator(sam)\n",
        "masks = mask_generator.generate(imagen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiofBidC5T6N"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Assign SAM configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mostrar_anotaciones(anotaciones):\n",
        "    if len(anotaciones) > 0:\n",
        "        anotaciones_ordenadas = sorted(anotaciones, key=(lambda x: x['area']), reverse=True)\n",
        "        ax = plt.gca()\n",
        "        ax.set_autoscale_on(False)\n",
        "        img = np.ones((anotaciones_ordenadas[0]['segmentation'].shape[0], anotaciones_ordenadas[0]['segmentation'].shape[1], 4))\n",
        "        img[:,:,3] = 0\n",
        "        for anotacion in anotaciones_ordenadas:\n",
        "            m = anotacion['segmentation']\n",
        "            color_mask = np.concatenate([np.random.random(3), [0.35]])  # Generar un color aleatorio con una transparencia del 35%\n",
        "            img[m] = color_mask\n",
        "        ax.imshow(img)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Imagen Original\")\n",
        "plt.imshow(imagen)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Segmentación SAM\")\n",
        "plt.imshow(imagen)\n",
        "mostrar_anotaciones(masks)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Watershep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gray = cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "_, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "kernel = np.ones((3, 3), np.uint8)\n",
        "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "_, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "sure_fg = np.uint8(sure_fg)\n",
        "unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "_, markers = cv2.connectedComponents(sure_fg)\n",
        "markers = markers + 1\n",
        "markers[unknown == 255] = 0\n",
        "\n",
        "imagen_watershed = imagen.copy()\n",
        "cv2.watershed(imagen_watershed, markers)\n",
        "imagen_watershed[markers == -1] = [255, 0, 0]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Imagen Original\")\n",
        "plt.imshow(imagen)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Segmentación Watershed\")\n",
        "plt.imshow(imagen_watershed)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
